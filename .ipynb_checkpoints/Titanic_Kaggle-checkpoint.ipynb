{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd7f4ccb-c413-4390-b28d-48bab85614b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "training_set = pd.read_csv('train.csv')\n",
    "test_set = pd.read_csv('test.csv')\n",
    "training_set.head()\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a41c57d-bc13-468b-8a50-61bcb7b2b269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = training_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a84a5b1c-91b6-4d69-8ae9-022d86a26337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin\n",
       "B96 B98        4\n",
       "G6             4\n",
       "C23 C25 C27    4\n",
       "C22 C26        3\n",
       "F33            3\n",
       "              ..\n",
       "E34            1\n",
       "C7             1\n",
       "C54            1\n",
       "E36            1\n",
       "C148           1\n",
       "Name: count, Length: 147, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.isna().sum()\n",
    "training_set['Cabin'].value_counts()\n",
    "#training_set['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c012a4a8-e385-4895-8943-6b5f6fefd7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "################ HANDLING MISSING DATA AND EXTRACINTG FEATURES ################\n",
    "###############################################################################\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "mean_imputer = SimpleImputer(strategy=\"mean\")\n",
    "most_frequent_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "training_set[['Age']] = mean_imputer.fit_transform(training_set[['Age']])\n",
    "training_set[['Embarked']] = most_frequent_imputer.fit_transform(training_set[['Embarked']])\n",
    "\n",
    "training_set['Cabin'] = training_set['Cabin'].fillna('Missing')\n",
    "training_set['Deck'] = training_set['Cabin'].str[0]\n",
    "training_set['HasCabin'] = (training_set['Cabin'] != 'Missing').astype(int)\n",
    "training_set['CabinCount'] = training_set['Cabin'].apply(lambda x:0 if x != 'Missing' else len(x.split()))\n",
    "training_set['Title'] = training_set['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\n",
    "training_set = training_set.drop(columns=['Name']) #===== DROPPING THE TITLE COLUMN BECAUSE I EXTRACTED TITLE FROM IT\n",
    "training_set = training_set.drop(columns=['Cabin']) #===== DROPPING THE CABIN COLUMN BECAUSE I EXTRACTED USEFUL FEATURES OUT OF IT\n",
    "training_set = training_set.drop(columns=['Ticket']) #===== DROPPING THE TICKET COLUMN BECAUSE IT SERVES NO PURPOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a19e345-0803-463e-b2a7-f1863e64161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "########################## ENCODING CATEGORICAL DATA ##########################\n",
    "###############################################################################\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#================================================================================#\n",
    "#==================== APPLYING LABEL ENCODING TO 'SEX' COLUMN ===================#\n",
    "#================================================================================#\n",
    "le = LabelEncoder()\n",
    "training_set[\"Sex\"] = le.fit_transform(training_set[\"Sex\"])\n",
    "\n",
    "#==================================================================================#\n",
    "#======= APPLYING ONE HOT ENCODING TO 'DECK', 'TITLE' AND 'EMBARKED' COLUMNS ======#\n",
    "#==================================================================================#\n",
    "encoder = OneHotEncoder(sparse_output = False, handle_unknown = \"ignore\")\n",
    "encoded_training = encoder.fit_transform(training_set[[\"Deck\", \"Title\", \"Embarked\"]])\n",
    "\n",
    "# Convert back to DataFrame with column names\n",
    "encoded_df = pd.DataFrame(encoded_training, columns=encoder.get_feature_names_out([\"Deck\", \"Title\", \"Embarked\"]), index = training_set.index)\n",
    "\n",
    "# Combine with original data (dropping the old column)\n",
    "training_set = pd.concat([training_set.reset_index(drop=True), encoded_df], axis=1).drop(columns=[\"Deck\", \"Title\", \"Embarked\"])\n",
    "\n",
    "#==================================================================================#\n",
    "#========================= SCALING 'FARE' AND 'AGE' COLUMNS =======================#\n",
    "#==================================================================================#\n",
    "scaler = StandardScaler()\n",
    "cols_to_scale = ['Age', 'Fare']\n",
    "training_set[cols_to_scale] = scaler.fit_transform(training_set[cols_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcad0685-a40d-4429-93cd-729901302c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>HasCabin</th>\n",
       "      <th>CabinCount</th>\n",
       "      <th>...</th>\n",
       "      <th>Title_Mlle</th>\n",
       "      <th>Title_Mme</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Sir</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.592481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.502445</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.638789</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.786845</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.284663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488854</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.420730</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.486337</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex       Age  SibSp  Parch      Fare  \\\n",
       "0            1         0       3    1 -0.592481      1      0 -0.502445   \n",
       "1            2         1       1    0  0.638789      1      0  0.786845   \n",
       "2            3         1       3    0 -0.284663      0      0 -0.488854   \n",
       "3            4         1       1    0  0.407926      1      0  0.420730   \n",
       "4            5         0       3    1  0.407926      0      0 -0.486337   \n",
       "\n",
       "   HasCabin  CabinCount  ...  Title_Mlle  Title_Mme  Title_Mr  Title_Mrs  \\\n",
       "0         0           1  ...         0.0        0.0       1.0        0.0   \n",
       "1         1           0  ...         0.0        0.0       0.0        1.0   \n",
       "2         0           1  ...         0.0        0.0       0.0        0.0   \n",
       "3         1           0  ...         0.0        0.0       0.0        1.0   \n",
       "4         0           1  ...         0.0        0.0       1.0        0.0   \n",
       "\n",
       "   Title_Ms  Title_Rev  Title_Sir  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0       0.0        0.0        0.0         0.0         0.0         1.0  \n",
       "1       0.0        0.0        0.0         1.0         0.0         0.0  \n",
       "2       0.0        0.0        0.0         0.0         0.0         1.0  \n",
       "3       0.0        0.0        0.0         0.0         0.0         1.0  \n",
       "4       0.0        0.0        0.0         0.0         0.0         1.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2293f33a-4322-4dd2-bf71-5f1a4153f0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "X = training_set.drop([\"PassengerId\", \"Survived\"], axis = 1)\n",
    "y = training_set['Survived']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "# sk_folds = StratifiedKFold(n_splits = 5)\n",
    "# # 3. Train and evaluate\n",
    "# for name, model in models.items():\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_val)\n",
    "#     cv_score = cross_val_score(model, X_train, y_train, cv =  sk_folds)\n",
    "#     print(f\"--- {name} ---\")\n",
    "#     print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "#     print(\"Precision:\", precision_score(y_val, y_pred))\n",
    "#     print(\"Recall:\", recall_score(y_val, y_pred))\n",
    "#     print(\"F1-score:\", f1_score(y_val, y_pred))\n",
    "#     print(\"Cross-Val Score: \", cv_score)\n",
    "    \n",
    "#     print()\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=models[\"Random Forest\"],\n",
    "    param_grid=param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368c12e9-4ea4-4d48-9db4-66b31eef8dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45cbc65f-3d69-48f5-aeda-06665e4eba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "########### HANDLING MISSING DATA AND EXTRACINTG FEATURES (FOR THE TEST SET) ###########\n",
    "###############################################################################\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "mean_imputer = SimpleImputer(strategy=\"mean\")\n",
    "most_frequent_imputer = SimpleImputer(strategy='most_frequent')\n",
    "test_set_copy = test_set.copy()\n",
    "\n",
    "test_set_copy[['Age']] = mean_imputer.fit_transform(test_set_copy[['Age']])\n",
    "test_set_copy[['Embarked']] = most_frequent_imputer.fit_transform(test_set_copy[['Embarked']])\n",
    "\n",
    "test_set_copy['Cabin'] = test_set_copy['Cabin'].fillna('Missing')\n",
    "test_set_copy['Deck'] = test_set_copy['Cabin'].str[0]\n",
    "test_set_copy['HasCabin'] = (test_set_copy['Cabin'] != 'Missing').astype(int)\n",
    "test_set_copy['CabinCount'] = test_set_copy['Cabin'].apply(lambda x:0 if x != 'Missing' else len(x.split()))\n",
    "test_set_copy['Title'] = test_set_copy['Name'].str.extract(' ([A-Za-z]+)\\\\.', expand=False)\n",
    "test_set_copy = test_set_copy.drop(columns=['Name']) #===== DROPPING THE TITLE COLUMN BECAUSE I EXTRACTED TITLE FROM IT\n",
    "test_set_copy = test_set_copy.drop(columns=['Cabin']) #===== DROPPING THE CABIN COLUMN BECAUSE I EXTRACTED USEFUL FEATURES OUT OF IT\n",
    "test_set_copy = test_set_copy.drop(columns=['Ticket']) #===== DROPPING THE TICKET COLUMN BECAUSE IT SERVES NO PURPOSE\n",
    "test_set_copy[\"Fare\"] = test_set_copy[\"Fare\"].fillna(training_set[\"Fare\"].median())\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "########################## ENCODING CATEGORICAL DATA ##########################\n",
    "###############################################################################\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#================================================================================#\n",
    "#==================== APPLYING LABEL ENCODING TO 'SEX' COLUMN ===================#\n",
    "#================================================================================#\n",
    "le = LabelEncoder()\n",
    "test_set_copy[\"Sex\"] = le.fit_transform(test_set_copy[\"Sex\"])\n",
    "\n",
    "#==================================================================================#\n",
    "#======= APPLYING ONE HOT ENCODING TO 'DECK', 'TITLE' AND 'EMBARKED' COLUMNS ======#\n",
    "#==================================================================================#\n",
    "encoded_test = encoder.transform(test_set_copy[[\"Deck\", \"Title\", \"Embarked\"]])\n",
    "\n",
    "# Convert back to DataFrame with column names\n",
    "encoded_df = pd.DataFrame(encoded_test, columns=encoder.get_feature_names_out([\"Deck\", \"Title\", \"Embarked\"]), index = test_set_copy.index)\n",
    "\n",
    "# Combine with original data (dropping the old column)\n",
    "test_set_copy = pd.concat([test_set_copy.reset_index(drop=True), encoded_df], axis=1).drop(columns=[\"Deck\", \"Title\", \"Embarked\"])\n",
    "\n",
    "#==================================================================================#\n",
    "#========================= SCALING 'FARE' AND 'AGE' COLUMNS =======================#\n",
    "#==================================================================================#\n",
    "scaler = StandardScaler()\n",
    "cols_to_scale = ['Age', 'Fare']\n",
    "test_set_copy[cols_to_scale] = scaler.fit_transform(test_set_copy[cols_to_scale])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a314c0e2-61c5-4cce-8014-a09f43c2569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predictions = models[\"Gradient Boosting\"].predict(test_set_copy)\n",
    "\n",
    "# submission = pd.DataFrame({\n",
    "#     'PassengerId': test_set_copy['PassengerId'],\n",
    "#     'Survived': predictions\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec3242e7-3335-41bd-b277-b01e4c951b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "Title_Mlle        0\n",
       "Title_Don         0\n",
       "Title_Dr          0\n",
       "Title_Jonkheer    0\n",
       "Title_Lady        0\n",
       "Title_Major       0\n",
       "Title_Master      0\n",
       "Title_Miss        0\n",
       "Title_Mme         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_copy.head()\n",
    "test_set_copy.isna().sum().sort_values(ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6fa7a76-81f6-4f4c-8b86-d5fed2c28b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch',\n",
       "       'Fare', 'HasCabin', 'CabinCount', 'Deck_A', 'Deck_B', 'Deck_C',\n",
       "       'Deck_D', 'Deck_E', 'Deck_F', 'Deck_G', 'Deck_M', 'Deck_T',\n",
       "       'Title_Capt', 'Title_Col', 'Title_Countess', 'Title_Don', 'Title_Dr',\n",
       "       'Title_Jonkheer', 'Title_Lady', 'Title_Major', 'Title_Master',\n",
       "       'Title_Miss', 'Title_Mlle', 'Title_Mme', 'Title_Mr', 'Title_Mrs',\n",
       "       'Title_Ms', 'Title_Rev', 'Title_Sir', 'Embarked_C', 'Embarked_Q',\n",
       "       'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aafb6159-b099-449a-acc9-ca20701db387",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m X_test \u001b[38;5;241m=\u001b[39m test_set_copy\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassengerId\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# predictions = models[\"Gradient Boosting\"].predict(X_test)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m grid_search_rf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      6\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassengerId\u001b[39m\u001b[38;5;124m\"\u001b[39m: passenger_ids,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m\"\u001b[39m: predictions\n\u001b[1;32m      9\u001b[0m })\n\u001b[1;32m     10\u001b[0m submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:596\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;129m@available_if\u001b[39m(_estimator_has(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    579\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[1;32m    580\u001b[0m \n\u001b[1;32m    581\u001b[0m \u001b[38;5;124;03m    Only available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;124;03m        the best found parameters.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 596\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1661\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "passenger_ids = test_set_copy[\"PassengerId\"]\n",
    "X_test = test_set_copy.drop(columns=[\"PassengerId\"])\n",
    "# predictions = models[\"Gradient Boosting\"].predict(X_test)\n",
    "predictions = grid_search_rf.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": passenger_ids,\n",
    "    \"Survived\": predictions\n",
    "})\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77894b3b-5c55-4e1c-9a64-5032264d27e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
